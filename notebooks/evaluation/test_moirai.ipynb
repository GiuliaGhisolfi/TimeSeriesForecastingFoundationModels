{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5659025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from src.evaluation.save_results import create_output_file, save_results\n",
    "\n",
    "output_file_name = \"moirai_small_test_results1.csv\"\n",
    "\n",
    "output_dir=\"results/test\"\n",
    "csv_file_path = os.path.join(output_dir, output_file_name)\n",
    "\n",
    "create_output_file(output_file_name, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ffa6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.model import evaluate_model\n",
    "from gluonts.time_feature import get_seasonality\n",
    "from src.evaluation.load_chronos_data import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4429873e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluation.metrics import get_metrics\n",
    "\n",
    "# Instantiate the metrics\n",
    "metrics = get_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340f5d5e",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ab7e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "short_datasets = \"solar/10T solar/H solar/D solar/W jena_weather/10T jena_weather/H jena_weather/D \" \\\n",
    "\"bitbrains_fast_storage/5T bitbrains_fast_storage/H bitbrains_rnd/5T bitbrains_rnd/H bizitobs_application \" \\\n",
    "\"bizitobs_service bizitobs_l2c/5T bizitobs_l2c/H\"\n",
    "\n",
    "med_long_datasets = \"solar/10T solar/H jena_weather/10T jena_weather/H \" \\\n",
    "\"bitbrains_fast_storage/5T bitbrains_rnd/5T bizitobs_application bizitobs_service bizitobs_l2c/5T bizitobs_l2c/H\"\n",
    "\n",
    "# Get union of short and med_long datasets\n",
    "all_datasets = list(set(short_datasets.split() + med_long_datasets.split()))\n",
    "\n",
    "dataset_properties_map = json.load(open(\"./data/dataset_properties.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee355eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluation.load_data import load_gift_data\n",
    "\n",
    "load_gift_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a2a11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = [\n",
    "    'bizitobs_l2c/5T',\n",
    "    'bitbrains_fast_storage/5T',\n",
    "    'bitbrains_rnd/H',\n",
    "    'bizitobs_l2c/H',\n",
    "    'jena_weather/H',\n",
    "    'bizitobs_application',\n",
    "    'bizitobs_service',\n",
    "    'bitbrains_fast_storage/H',\n",
    "    'solar/D',\n",
    "    'jena_weather/10T',\n",
    "    'solar/W',\n",
    "    'jena_weather/D',\n",
    "    'bitbrains_rnd/5T',\n",
    "    'solar/10T',\n",
    "    'solar/H',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29123ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHRONOS_DATASET_NAME = [\n",
    "    #\"exchange_rate\", \n",
    "    \"ercot\", \"dominick\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b296a39",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3271f917",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"/raid/decaro/TimeSeriesForecastingFoundationModels/moirai_checkpoints/\"\n",
    "MODEL_NAME = \"moirai_small\"\n",
    "MODULE = \"Salesforce/moirai-1.1-R-small\"\n",
    "\n",
    "CHECKPOINTS = [f\"moirai_small_epoch_epoch={i}.ckpt\" for i in range(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746a02e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ff478c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d96ae20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluation.moirai_predictor import load_predictor\n",
    "from src.gift_eval.data import Dataset\n",
    "\n",
    "for train_step, model_name in enumerate(CHECKPOINTS):    \n",
    "    for ds_name in CHRONOS_DATASET_NAME:\n",
    "        print(f\"Processing dataset: {ds_name}\")\n",
    "\n",
    "        terms = [\"short\", \"medium\", \"long\"]\n",
    "        if ds_name == \"ercot\":\n",
    "            terms = [\"medium\", \"long\"]\n",
    "\n",
    "        for term in terms:\n",
    "            ds_config = f\"{ds_name}/{term}\"\n",
    "\n",
    "            dataset, prediction_length, frequency, domain, num_variates = load_data(ds_name, term)\n",
    "            season_length = get_seasonality(frequency)\n",
    "\n",
    "            predictor = load_predictor(\n",
    "                checkpoint=MODEL_PATH+model_name, \n",
    "                module=MODULE,\n",
    "                prediction_length=prediction_length, \n",
    "                target_dim=num_variates,\n",
    "                device_map=\"cpu\"\n",
    "                )\n",
    "\n",
    "            res = evaluate_model(\n",
    "                predictor,\n",
    "                test_data=dataset,\n",
    "                metrics=metrics,\n",
    "                batch_size=1024,\n",
    "                axis=None,\n",
    "                mask_invalid_label=True,\n",
    "                allow_nan_forecast=False,\n",
    "                seasonality=season_length,\n",
    "            )\n",
    "\n",
    "            # Append the results to the CSV file\n",
    "            save_results(res, ds_config, MODEL_NAME, train_step, domain, num_variates, ds_name, csv_file_path)\n",
    "\n",
    "    for ds_name in DATASET_NAME:\n",
    "        ds_key = ds_name.split(\"/\")[0]\n",
    "        print(f\"Processing dataset: {ds_name}\")\n",
    "        terms = [\"short\", \"medium\", \"long\"]\n",
    "        for term in terms:\n",
    "            if (\n",
    "                term == \"medium\" or term == \"long\"\n",
    "            ) and ds_name not in med_long_datasets.split():\n",
    "                continue\n",
    "\n",
    "            if \"/\" in ds_name:\n",
    "                ds_key = ds_name.split(\"/\")[0]\n",
    "                ds_freq = ds_name.split(\"/\")[1]\n",
    "                ds_key = ds_key.lower()\n",
    "            else:\n",
    "                ds_key = ds_name.lower()\n",
    "                ds_freq = dataset_properties_map[ds_key][\"frequency\"]\n",
    "            ds_config = f\"{ds_key}/{ds_freq}/{term}\"\n",
    "\n",
    "            # Initialize the dataset\n",
    "            to_univariate = (\n",
    "                False\n",
    "                if Dataset(name=ds_name, term=term, to_univariate=False).target_dim == 1\n",
    "                else True\n",
    "            )\n",
    "            dataset = Dataset(name=ds_name, term=term, to_univariate=to_univariate)\n",
    "            season_length = get_seasonality(dataset.freq)\n",
    "\n",
    "            predictor = load_predictor(\n",
    "                checkpoint=MODEL_PATH+model_name, \n",
    "                module=MODULE,\n",
    "                prediction_length=dataset.prediction_length, \n",
    "                target_dim=dataset.target_dim,\n",
    "                device_map=\"cpu\"\n",
    "                )\n",
    "\n",
    "            # Measure the time taken for evaluation\n",
    "            res = evaluate_model(\n",
    "                predictor,\n",
    "                test_data=dataset.test_data,\n",
    "                metrics=metrics,\n",
    "                batch_size=1024,\n",
    "                axis=None,\n",
    "                mask_invalid_label=True,\n",
    "                allow_nan_forecast=False,\n",
    "                seasonality=season_length,\n",
    "            )\n",
    "\n",
    "            # Append the results to the CSV file\n",
    "            save_results(res, ds_config, MODEL_NAME, train_step, domain, num_variates, ds_name, csv_file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moirai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
