{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5659025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from src.evaluation.save_results import create_output_file, save_results\n",
    "\n",
    "output_file_name = \"moirai_small_test_results.csv\"\n",
    "\n",
    "output_dir=\"results/test\"\n",
    "csv_file_path = os.path.join(output_dir, output_file_name)\n",
    "\n",
    "create_output_file(output_file_name, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5ffa6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.model import evaluate_model\n",
    "from gluonts.time_feature import get_seasonality\n",
    "from src.evaluation.load_chronos_data import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4429873e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluation.metrics import get_metrics\n",
    "\n",
    "# Instantiate the metrics\n",
    "metrics = get_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340f5d5e",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9ab7e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "short_datasets = \"solar/10T solar/H solar/D solar/W jena_weather/10T jena_weather/H jena_weather/D \" \\\n",
    "\"bitbrains_fast_storage/5T bitbrains_fast_storage/H bitbrains_rnd/5T bitbrains_rnd/H bizitobs_application \" \\\n",
    "\"bizitobs_service bizitobs_l2c/5T bizitobs_l2c/H\"\n",
    "\n",
    "med_long_datasets = \"solar/10T solar/H jena_weather/10T jena_weather/H \" \\\n",
    "\"bitbrains_fast_storage/5T bitbrains_rnd/5T bizitobs_application bizitobs_service bizitobs_l2c/5T bizitobs_l2c/H\"\n",
    "\n",
    "# Get union of short and med_long datasets\n",
    "all_datasets = list(set(short_datasets.split() + med_long_datasets.split()))\n",
    "\n",
    "dataset_properties_map = json.load(open(\"./data/dataset_properties.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee355eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/valerio/miniconda3/envs/moirai/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/valerio/miniconda3/envs/moirai/lib/python3.9/site-packages/huggingface_hub/file_download.py:980: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n",
      "For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n",
      "  warnings.warn(\n",
      "Fetching 175 files: 100%|██████████| 175/175 [00:00<00:00, 1366.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available datasets in GIFT_EVAL:\n",
      "- LOOP_SEATTLE/5T\n",
      "- LOOP_SEATTLE/D\n",
      "- LOOP_SEATTLE/H\n",
      "- M_DENSE/D\n",
      "- M_DENSE/H\n",
      "- SZ_TAXI/15T\n",
      "- SZ_TAXI/H\n",
      "- bitbrains_fast_storage/5T\n",
      "- bitbrains_fast_storage/H\n",
      "- bitbrains_rnd/5T\n",
      "- bitbrains_rnd/H\n",
      "- bizitobs_application\n",
      "- bizitobs_l2c/5T\n",
      "- bizitobs_l2c/H\n",
      "- bizitobs_service\n",
      "- car_parts_with_missing\n",
      "- covid_deaths\n",
      "- electricity/15T\n",
      "- electricity/D\n",
      "- electricity/H\n",
      "- electricity/W\n",
      "- ett1/15T\n",
      "- ett1/D\n",
      "- ett1/H\n",
      "- ett1/W\n",
      "- ett2/15T\n",
      "- ett2/D\n",
      "- ett2/H\n",
      "- ett2/W\n",
      "- hierarchical_sales/D\n",
      "- hierarchical_sales/W\n",
      "- hospital\n",
      "- jena_weather/10T\n",
      "- jena_weather/D\n",
      "- jena_weather/H\n",
      "- kdd_cup_2018_with_missing/D\n",
      "- kdd_cup_2018_with_missing/H\n",
      "- m4_daily\n",
      "- m4_hourly\n",
      "- m4_monthly\n",
      "- m4_quarterly\n",
      "- m4_weekly\n",
      "- m4_yearly\n",
      "- restaurant\n",
      "- saugeenday/D\n",
      "- saugeenday/M\n",
      "- saugeenday/W\n",
      "- solar/10T\n",
      "- solar/D\n",
      "- solar/H\n",
      "- solar/W\n",
      "- temperature_rain_with_missing\n",
      "- us_births/D\n",
      "- us_births/M\n",
      "- us_births/W\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from src.evaluation.load_data import load_gift_data\n",
    "\n",
    "load_gift_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93a2a11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = [\n",
    "    'bizitobs_l2c/5T',\n",
    "    'bitbrains_fast_storage/5T',\n",
    "    'bitbrains_rnd/H',\n",
    "    'bizitobs_l2c/H',\n",
    "    'jena_weather/H',\n",
    "    'bizitobs_application',\n",
    "    'bizitobs_service',\n",
    "    'bitbrains_fast_storage/H',\n",
    "    'solar/D',\n",
    "    'jena_weather/10T',\n",
    "    'solar/W',\n",
    "    'jena_weather/D',\n",
    "    'bitbrains_rnd/5T',\n",
    "    'solar/10T',\n",
    "    'solar/H',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f29123ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHRONOS_DATASET_NAME = [\n",
    "    #\"exchange_rate\", \n",
    "    \"ercot\", \"dominick\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b296a39",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3271f917",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"moirai_checkpoints/\"\n",
    "MODEL_NAME = \"moirai_small\"\n",
    "MODULE = \"Salesforce/moirai-1.1-R-small\"\n",
    "\n",
    "CHECKPOINTS = [f\"moirai_small_epoch_epoch={i}.ckpt\" for i in range(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "746a02e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0ff478c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d96ae20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset: ercot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/valerio/miniconda3/envs/moirai/lib/python3.9/site-packages/gluonts/dataset/common.py:255: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  ProcessDataEntry(to_offset(freq), one_dim_target, use_timestamp),\n",
      "/home/valerio/miniconda3/envs/moirai/lib/python3.9/site-packages/gluonts/time_feature/seasonality.py:47: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  offset = pd.tseries.frequencies.to_offset(freq)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No CUDA GPUs are available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m dataset, prediction_length, frequency, domain, num_variates \u001b[38;5;241m=\u001b[39m load_data(ds_name, term)\n\u001b[1;32m     16\u001b[0m season_length \u001b[38;5;241m=\u001b[39m get_seasonality(frequency)\n\u001b[0;32m---> 18\u001b[0m predictor \u001b[38;5;241m=\u001b[39m \u001b[43mload_predictor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMODEL_PATH\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMODULE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprediction_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_variates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m res \u001b[38;5;241m=\u001b[39m evaluate_model(\n\u001b[1;32m     27\u001b[0m     predictor,\n\u001b[1;32m     28\u001b[0m     test_data\u001b[38;5;241m=\u001b[39mdataset,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m     seasonality\u001b[38;5;241m=\u001b[39mseason_length,\n\u001b[1;32m     35\u001b[0m )\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Append the results to the CSV file\u001b[39;00m\n",
      "File \u001b[0;32m~/TimeSeriesForecastingFoundationModels/src/evaluation/moirai_predictor.py:16\u001b[0m, in \u001b[0;36mload_predictor\u001b[0;34m(checkpoint, module, prediction_length, target_dim, device_map)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_predictor\u001b[39m(checkpoint: \u001b[38;5;28mstr\u001b[39m, module: \u001b[38;5;28mstr\u001b[39m, prediction_length: \u001b[38;5;28mint\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, target_dim: \u001b[38;5;28mint\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, \n\u001b[1;32m      6\u001b[0m     device_map: \u001b[38;5;28mstr\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      7\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m    Load a model by its name.\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m        object: The loaded model.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     pretrained_module \u001b[38;5;241m=\u001b[39m \u001b[43mMoiraiModule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     finetuned_model \u001b[38;5;241m=\u001b[39m MoiraiFinetune\u001b[38;5;241m.\u001b[39mload_from_checkpoint(\n\u001b[1;32m     19\u001b[0m         checkpoint_path\u001b[38;5;241m=\u001b[39mcheckpoint,\n\u001b[1;32m     20\u001b[0m         module\u001b[38;5;241m=\u001b[39mpretrained_module,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m         log_on_step\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     34\u001b[0m     )\u001b[38;5;241m.\u001b[39mto(device_map)\n\u001b[1;32m     36\u001b[0m     model \u001b[38;5;241m=\u001b[39m MoiraiForecast(\n\u001b[1;32m     37\u001b[0m         module\u001b[38;5;241m=\u001b[39mfinetuned_model\u001b[38;5;241m.\u001b[39mmodule,\n\u001b[1;32m     38\u001b[0m         prediction_length\u001b[38;5;241m=\u001b[39mprediction_length,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m         past_feat_dynamic_real_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     45\u001b[0m     )\u001b[38;5;241m.\u001b[39mto(device_map)\n",
      "File \u001b[0;32m~/miniconda3/envs/moirai/lib/python3.9/site-packages/torch/nn/modules/module.py:927\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    924\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m    925\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> 927\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/moirai/lib/python3.9/site-packages/torch/nn/modules/module.py:579\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 579\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    584\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    590\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/moirai/lib/python3.9/site-packages/torch/nn/modules/module.py:602\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 602\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/miniconda3/envs/moirai/lib/python3.9/site-packages/torch/nn/modules/module.py:925\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m    923\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    924\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m--> 925\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/moirai/lib/python3.9/site-packages/torch/cuda/__init__.py:217\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    215\u001b[0m \u001b[38;5;66;03m# This function throws if there's a driver initialization error, no GPUs\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;66;03m# are found or any other error occurs\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    221\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
     ]
    }
   ],
   "source": [
    "from src.evaluation.moirai_predictor import load_predictor\n",
    "from src.gift_eval.data import Dataset\n",
    "\n",
    "for train_step, model_name in enumerate(CHECKPOINTS):    \n",
    "    for ds_name in CHRONOS_DATASET_NAME:\n",
    "        print(f\"Processing dataset: {ds_name}\")\n",
    "\n",
    "        terms = [\"short\", \"medium\", \"long\"]\n",
    "        if ds_name == \"ercot\":\n",
    "            terms = [\"medium\", \"long\"]\n",
    "\n",
    "        for term in terms:\n",
    "            ds_config = f\"{ds_name}/{term}\"\n",
    "\n",
    "            dataset, prediction_length, frequency, domain, num_variates = load_data(ds_name, term)\n",
    "            season_length = get_seasonality(frequency)\n",
    "\n",
    "            predictor = load_predictor(\n",
    "                checkpoint=MODEL_PATH+model_name, \n",
    "                module=MODULE,\n",
    "                prediction_length=prediction_length, \n",
    "                target_dim=num_variates,\n",
    "                device_map=\"cpu\"\n",
    "                )\n",
    "\n",
    "            res = evaluate_model(\n",
    "                predictor,\n",
    "                test_data=dataset,\n",
    "                metrics=metrics,\n",
    "                batch_size=1024,\n",
    "                axis=None,\n",
    "                mask_invalid_label=True,\n",
    "                allow_nan_forecast=False,\n",
    "                seasonality=season_length,\n",
    "            )\n",
    "\n",
    "            # Append the results to the CSV file\n",
    "            save_results(res, ds_config, MODEL_NAME, train_step, domain, num_variates, ds_name, csv_file_path)\n",
    "\n",
    "    for ds_name in DATASET_NAME:\n",
    "        ds_key = ds_name.split(\"/\")[0]\n",
    "        print(f\"Processing dataset: {ds_name}\")\n",
    "        terms = [\"short\", \"medium\", \"long\"]\n",
    "        for term in terms:\n",
    "            if (\n",
    "                term == \"medium\" or term == \"long\"\n",
    "            ) and ds_name not in med_long_datasets.split():\n",
    "                continue\n",
    "\n",
    "            if \"/\" in ds_name:\n",
    "                ds_key = ds_name.split(\"/\")[0]\n",
    "                ds_freq = ds_name.split(\"/\")[1]\n",
    "                ds_key = ds_key.lower()\n",
    "            else:\n",
    "                ds_key = ds_name.lower()\n",
    "                ds_freq = dataset_properties_map[ds_key][\"frequency\"]\n",
    "            ds_config = f\"{ds_key}/{ds_freq}/{term}\"\n",
    "\n",
    "            # Initialize the dataset\n",
    "            to_univariate = (\n",
    "                False\n",
    "                if Dataset(name=ds_name, term=term, to_univariate=False).target_dim == 1\n",
    "                else True\n",
    "            )\n",
    "            dataset = Dataset(name=ds_name, term=term, to_univariate=to_univariate)\n",
    "            season_length = get_seasonality(dataset.freq)\n",
    "\n",
    "            predictor = load_predictor(\n",
    "                checkpoint=MODEL_PATH+model_name, \n",
    "                module=MODULE,\n",
    "                prediction_length=dataset.prediction_length, \n",
    "                target_dim=dataset.target_dim,\n",
    "                device_map=\"cpu\"\n",
    "                )\n",
    "\n",
    "            # Measure the time taken for evaluation\n",
    "            res = evaluate_model(\n",
    "                predictor,\n",
    "                test_data=dataset.test_data,\n",
    "                metrics=metrics,\n",
    "                batch_size=1024,\n",
    "                axis=None,\n",
    "                mask_invalid_label=True,\n",
    "                allow_nan_forecast=False,\n",
    "                seasonality=season_length,\n",
    "            )\n",
    "\n",
    "            # Append the results to the CSV file\n",
    "            save_results(res, ds_config, MODEL_NAME, train_step, domain, num_variates, ds_name, csv_file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moirai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
