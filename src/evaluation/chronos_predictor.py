import logging
from dataclasses import dataclass, field
from typing import List, Optional

import numpy as np
import torch
from gluonts.itertools import batcher
from gluonts.model import Forecast
from gluonts.model.forecast import QuantileForecast, SampleForecast
from tqdm.auto import tqdm

from src.chronos import BaseChronosPipeline, ForecastType

from transformers import AutoConfig
from src.chronos.chronos_bolt import ChronosBoltConfig

def clean_chronos_config(kwargs):
    if "chronos_config" in kwargs:
        # Ottieni i nomi degli argomenti accettati dal costruttore di ChronosBoltConfig
        accepted_keys = ChronosBoltConfig.__init__.__code__.co_varnames
        accepted_keys = set(accepted_keys) - {"self", "args", "kwargs"}
        
        # Filtra solo quelli accettati
        kwargs["chronos_config"] = {
            k: v for k, v in kwargs["chronos_config"].items()
            if k in accepted_keys
        }
    return kwargs

@dataclass
class ModelConfig:
    quantile_levels: Optional[List[float]] = None
    forecast_keys: List[str] = field(init=False)
    statsforecast_keys: List[str] = field(init=False)
    intervals: Optional[List[int]] = field(init=False)

    def __post_init__(self):
        self.forecast_keys = ["mean"]
        self.statsforecast_keys = ["mean"]
        if self.quantile_levels is None:
            self.intervals = None
            return

        intervals = set()

        for quantile_level in self.quantile_levels:
            interval = round(200 * (max(quantile_level, 1 - quantile_level) - 0.5))
            intervals.add(interval)
            side = "hi" if quantile_level > 0.5 else "lo"
            self.forecast_keys.append(str(quantile_level))
            self.statsforecast_keys.append(f"{side}-{interval}")

        self.intervals = sorted(intervals)

class WarningFilter(logging.Filter):
    def __init__(self, text_to_filter):
        super().__init__()
        self.text_to_filter = text_to_filter

    def filter(self, record):
        return self.text_to_filter not in record.getMessage()

class ChronosPredictor:
    def __init__(
        self,
        model_path,
        num_samples: int,
        prediction_length: int,
        *args,
        **kwargs,
    ):
        gts_logger = logging.getLogger("gluonts.model.forecast")
        gts_logger.addFilter(
            WarningFilter("The mean prediction is not stored in the forecast data")
        )

        print("prediction_length:", prediction_length)
        kwargs = {
            "chronos_config": AutoConfig.from_pretrained(model_path).chronos_config,
        }
        kwargs = clean_chronos_config(kwargs)
        kwargs["chronos_config"].update({
            "input_patch_size": 16,
            "input_patch_stride": 8,
            "quantiles": [0.1, 0.5, 0.9],
        })

        self.pipeline = BaseChronosPipeline.from_pretrained(
            model_path,
            ignore_mismatched_sizes=True,
            *args,
            **kwargs,
        )
        self.prediction_length = prediction_length
        self.num_samples = num_samples

    def predict(self, test_data_input, batch_size: int = 1024) -> List[Forecast]:
        pipeline = self.pipeline
        predict_kwargs = (
            {"num_samples": self.num_samples}
            if pipeline.forecast_type == ForecastType.SAMPLES
            else {}
        )
        while True:
            try:
                # Generate forecast samples
                forecast_outputs = []
                for batch in tqdm(batcher(test_data_input, batch_size=batch_size)):
                    context = [torch.tensor(entry["target"]) for entry in batch]
                    forecast_outputs.append(
                        pipeline.predict(
                            context,
                            prediction_length=self.prediction_length,
                            **predict_kwargs,
                        ).numpy()
                    )
                forecast_outputs = np.concatenate(forecast_outputs)
                break
            except torch.cuda.OutOfMemoryError:
                print(
                    f"OutOfMemoryError at batch_size {batch_size}, reducing to {batch_size // 2}"
                )
                batch_size //= 2

        # Convert forecast samples into gluonts Forecast objects
        forecasts = []
        for item, ts in zip(forecast_outputs, test_data_input):
            forecast_start_date = ts["start"] + len(ts["target"])

            if pipeline.forecast_type == ForecastType.SAMPLES:
                forecasts.append(
                    SampleForecast(samples=item, start_date=forecast_start_date)
                )
            elif pipeline.forecast_type == ForecastType.QUANTILES:
                forecasts.append(
                    QuantileForecast(
                        forecast_arrays=item,
                        forecast_keys=list(map(str, pipeline.quantiles)),
                        start_date=forecast_start_date,
                    )
                )

        return forecasts